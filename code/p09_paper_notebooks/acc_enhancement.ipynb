{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7eff628",
   "metadata": {},
   "source": [
    "# Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf669a6d",
   "metadata": {},
   "source": [
    "This notebook contains the code to replicate select results from the [paper on arxiv](https://arxiv.org/abs/2504.06195)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441aa02c",
   "metadata": {},
   "source": [
    "# imports & load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4dd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170add6",
   "metadata": {},
   "source": [
    "## load matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7856284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TiTE\n",
    "all_data = {}\n",
    "all_data[\"Ti_TE\"] = pd.read_excel(\"../p04_TE_TM_1D_compare/Ti_TE_matrix.xlsx\", header=None).transpose()\n",
    "all_data[\"Ti_TE\"].columns = [f\"feature_{i+1}\" for i in range(all_data[\"Ti_TE\"].shape[1])]\n",
    "all_data[\"Ti_TE\"][\"target\"] = list(range(1, all_data[\"Ti_TE\"].shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175584f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in [\"Si_TE\", \"Si_TM\", \"Ti_TM\"]:\n",
    "    all_data[dat] = pd.read_excel(f\"../p06_multvar_SI_fitting/{dat}_matrix.xlsx\", header=None).transpose()\n",
    "    all_data[dat].columns = [f\"feature_{i+1}\" for i in range(all_data[dat].shape[1])]\n",
    "    all_data[dat][\"target\"] = list(range(1, all_data[dat].shape[0] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a7550",
   "metadata": {},
   "source": [
    "## build the 5-fold cross validation groups and construct PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088e0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 5-folds cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=19890417)\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "PC_folds = {}\n",
    "folds = {} # this will not use PC to reduce the data\n",
    "\n",
    "for dat in all_data.keys():\n",
    "    PC_folds[dat] = []\n",
    "    folds[dat] = []\n",
    "    full_data = all_data[dat].copy()\n",
    "    for train_index, test_index in kf.split(all_data[dat]):\n",
    "        # because this doesn't check for out of range values we need to make sure that we move any 0 or 100 index values from test to train\n",
    "        # if 0 in test_index:\n",
    "        #     test_index = np.delete(test_index, np.where(test_index == 0)[0][0])\n",
    "        #     train_index = np.append(train_index, 0)\n",
    "        # if 100 in test_index:\n",
    "        #     test_index = np.delete(test_index, np.where(test_index == 100)[0][0])\n",
    "        #     train_index = np.append(train_index, 100)\n",
    "        # train_index.sort()\n",
    "        # print(f\"train: {train_index}, test: {test_index}\")\n",
    "        train_data = full_data.iloc[train_index]\n",
    "        test_data = full_data.iloc[test_index]\n",
    "        # first put the raw data into the folds\n",
    "        folds[dat].append((train_data.drop(columns=[\"target\"]), train_data[\"target\"].values, test_data.drop(columns=[\"target\"]), test_data[\"target\"].values))\n",
    "        # now we also want to dimensionally reduce the data into 80 PCs following the training data\n",
    "        pca = PCA(n_components=80, svd_solver='full', random_state=19890417)\n",
    "        # first standardize the data according to the training data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data.drop(columns=[\"target\"]))\n",
    "        train_data_scaled = scaler.transform(train_data.drop(columns=[\"target\"]))\n",
    "        test_data_scaled = scaler.transform(test_data.drop(columns=[\"target\"]))\n",
    "        pca.fit(train_data_scaled)\n",
    "        train_data_pca = pca.transform(train_data_scaled)\n",
    "        test_data_pca = pca.transform(test_data_scaled)\n",
    "        PC_folds[dat].append((train_data_pca, train_data[\"target\"].values, test_data_pca, test_data[\"target\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b5d9a",
   "metadata": {},
   "source": [
    "# Identify best single variate performer for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2004f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 325.06it/s]\n",
      "100%|██████████| 10000/10000 [00:34<00:00, 289.81it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 246.68it/s]\n",
      "100%|██████████| 10000/10000 [00:39<00:00, 250.55it/s]\n",
      "100%|██████████| 10000/10000 [00:35<00:00, 278.34it/s]\n",
      "100%|██████████| 10000/10000 [00:36<00:00, 271.31it/s]\n",
      "100%|██████████| 10000/10000 [00:37<00:00, 263.37it/s]\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 302.71it/s]\n",
      "100%|██████████| 10000/10000 [00:30<00:00, 324.97it/s]\n",
      "100%|██████████| 10000/10000 [00:37<00:00, 266.66it/s]\n",
      "100%|██████████| 10000/10000 [00:36<00:00, 275.31it/s]\n",
      "100%|██████████| 10000/10000 [00:37<00:00, 268.79it/s]\n",
      "100%|██████████| 10000/10000 [00:32<00:00, 308.09it/s]\n",
      "100%|██████████| 10000/10000 [00:29<00:00, 334.57it/s]\n",
      "100%|██████████| 10000/10000 [00:36<00:00, 274.33it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 249.47it/s]\n",
      "100%|██████████| 10000/10000 [00:31<00:00, 320.62it/s]\n",
      "100%|██████████| 10000/10000 [00:29<00:00, 335.10it/s]\n",
      "100%|██████████| 10000/10000 [00:38<00:00, 262.26it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 223.22it/s]\n"
     ]
    }
   ],
   "source": [
    "results_dfs = {}\n",
    "for dat in [\"Ti_TM\", \"Ti_TE\", \"Si_TE\", \"Si_TM\"]:\n",
    "    result_list = []\n",
    "    fold_i = 0\n",
    "    for train_data_pca, train_target, test_data_pca, test_target in folds[dat]:\n",
    "        for feat_i in tqdm(range(train_data_pca.shape[1])):\n",
    "            X_train = train_data_pca[f\"feature_{feat_i+1}\"].to_numpy()\n",
    "            y_train = train_target\n",
    "            X_test = test_data_pca[f\"feature_{feat_i+1}\"].to_numpy()\n",
    "            y_test = test_target\n",
    "            # Fit a linear regression model\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train.reshape(-1, 1), y_train)\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "            # Calculate MSE, R2, RMSE, MAE\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = np.mean(np.abs(y_test - y_pred))\n",
    "            # now calculate the same metrics on the training data\n",
    "            y_train_pred = model.predict(X_train.reshape(-1, 1))\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = np.mean(np.abs(y_train - y_train_pred))\n",
    "            # Append results to the list\n",
    "            result_list.append({\n",
    "                \"feature\": f\"feature_{feat_i+1}\",\n",
    "                \"mse\": mse,\n",
    "                \"r2\": r2,\n",
    "                \"rmse\": rmse,\n",
    "                \"mae\": mae,\n",
    "                \"fold\": fold_i,\n",
    "                \"mse.train\": mse_train,\n",
    "                \"r2.train\": r2_train,\n",
    "                \"rmse.train\": rmse_train,\n",
    "                \"mae.train\": mae_train,\n",
    "            })\n",
    "        fold_i += 1\n",
    "    results_dfs[dat] = pd.DataFrame(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2bf7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Ti_TM\n",
      "Best feature: feature_5094 (train MSE: 0.4017 std (0.0247))\n",
      "Mean MSE: 0.4462 std (0.1050)\n",
      "Mean R2: 0.9994 std (0.0002)\n",
      "Mean RMSE: 0.6636 std (0.0855)\n",
      "Mean MAE: 0.5234 std (0.0653)\n",
      "\n",
      "Dataset: Ti_TE\n",
      "Best feature: feature_4956 (train MSE: 0.0628 std (0.0038))\n",
      "Mean MSE: 0.0655 std (0.0150)\n",
      "Mean R2: 0.9999 std (0.0000)\n",
      "Mean RMSE: 0.2547 std (0.0284)\n",
      "Mean MAE: 0.2151 std (0.0306)\n",
      "\n",
      "Dataset: Si_TE\n",
      "Best feature: feature_390 (train MSE: 0.2336 std (0.0204))\n",
      "Mean MSE: 0.2416 std (0.0866)\n",
      "Mean R2: 0.9997 std (0.0001)\n",
      "Mean RMSE: 0.4853 std (0.0873)\n",
      "Mean MAE: 0.4001 std (0.0558)\n",
      "\n",
      "Dataset: Si_TM\n",
      "Best feature: feature_1206 (train MSE: 0.1355 std (0.0089))\n",
      "Mean MSE: 0.1417 std (0.0378)\n",
      "Mean R2: 0.9998 std (0.0001)\n",
      "Mean RMSE: 0.3736 std (0.0509)\n",
      "Mean MAE: 0.3097 std (0.0525)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each dataset we want to print the mean and std of the metrics for the best feature\n",
    "# also save them to a lookup table\n",
    "best_results = {}\n",
    "for dat in [\"Ti_TM\", \"Ti_TE\", \"Si_TE\", \"Si_TM\"]:\n",
    "    print(f\"Dataset: {dat}\")\n",
    "    # first group by feature to find the feature with lowest mean mse\n",
    "    mean_results = results_dfs[dat].groupby(\"feature\").agg({\n",
    "        \"mse\": [\"mean\",\"std\"],\n",
    "        \"r2\": [\"mean\",\"std\"],\n",
    "        \"rmse\": [\"mean\",\"std\"],\n",
    "        \"mae\": [\"mean\",\"std\"],\n",
    "        \"mse.train\": [\"mean\",\"std\"],\n",
    "        \"r2.train\": [\"mean\",\"std\"],\n",
    "        \"rmse.train\": [\"mean\",\"std\"],\n",
    "        \"mae.train\": [\"mean\",\"std\"],\n",
    "    })\n",
    "    mean_results.columns = [\"_\".join(col).strip() for col in mean_results.columns.values]\n",
    "    mean_results = mean_results.reset_index()\n",
    "    # now we want to find the feature with the lowest mean mse for training\n",
    "    best_feature_idx = mean_results[\"mse.train_mean\"].idxmin()\n",
    "    best_feature = mean_results.iloc[best_feature_idx]\n",
    "    print(f\"Best feature: {best_feature['feature']} (train MSE: {best_feature['mse.train_mean']:.4f} std ({best_feature['mse.train_std']:.4f}))\")\n",
    "    print(f\"Mean MSE: {best_feature['mse_mean']:.4f} std ({best_feature['mse_std']:.4f})\")\n",
    "    print(f\"Mean R2: {best_feature['r2_mean']:.4f} std ({best_feature['r2_std']:.4f})\")\n",
    "    print(f\"Mean RMSE: {best_feature['rmse_mean']:.4f} std ({best_feature['rmse_std']:.4f})\")\n",
    "    print(f\"Mean MAE: {best_feature['mae_mean']:.4f} std ({best_feature['mae_std']:.4f})\")\n",
    "    print()\n",
    "    # save the best feature to the lookup table\n",
    "    best_results[dat] = {\n",
    "        \"feature\": best_feature[\"feature\"],\n",
    "        \"mse_mean\": best_feature[\"mse_mean\"],\n",
    "        \"mse_std\": best_feature[\"mse_std\"],\n",
    "        \"r2_mean\": best_feature[\"r2_mean\"],\n",
    "        \"r2_std\": best_feature[\"r2_std\"],\n",
    "        \"rmse_mean\": best_feature[\"rmse_mean\"],\n",
    "        \"rmse_std\": best_feature[\"rmse_std\"],\n",
    "        \"mae_mean\": best_feature[\"mae_mean\"],\n",
    "        \"mae_std\": best_feature[\"mae_std\"],\n",
    "        \"mse.train_mean\": best_feature[\"mse.train_mean\"],\n",
    "        \"mse.train_std\": best_feature[\"mse.train_std\"], \n",
    "        \"r2.train_mean\": best_feature[\"r2.train_mean\"],\n",
    "        \"r2.train_std\": best_feature[\"r2.train_std\"],\n",
    "        \"rmse.train_mean\": best_feature[\"rmse.train_mean\"],\n",
    "        \"rmse.train_std\": best_feature[\"rmse.train_std\"],\n",
    "        \"mae.train_mean\": best_feature[\"mae.train_mean\"],\n",
    "        \"mae.train_std\": best_feature[\"mae.train_std\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa92006",
   "metadata": {},
   "source": [
    "# Now Evaluate the performance when the entire peak is used (Figure 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ac9597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Ti_TM\n",
      "Mean MSE: 6.6233e-05 std (2.1992e-05). 6736.42x fold improvement\n",
      "Mean R2: 1.0000 std (0.0000). 1.00x fold improvement\n",
      "Mean RMSE: 0.0080 std (0.0014). 82.52x fold improvement\n",
      "Mean MAE: 0.0066 std (0.0010). 79.74x fold improvement\n",
      "\n",
      "Dataset: Ti_TE\n",
      "Mean MSE: 1.0488e-04 std (6.4012e-05). 624.73x fold improvement\n",
      "Mean R2: 1.0000 std (0.0000). 1.00x fold improvement\n",
      "Mean RMSE: 0.0099 std (0.0031). 25.82x fold improvement\n",
      "Mean MAE: 0.0072 std (0.0016). 29.84x fold improvement\n",
      "\n",
      "Dataset: Si_TE\n",
      "Mean MSE: 2.4732e-02 std (9.9685e-03). 9.77x fold improvement\n",
      "Mean R2: 1.0000 std (0.0000). 1.00x fold improvement\n",
      "Mean RMSE: 0.1547 std (0.0314). 3.14x fold improvement\n",
      "Mean MAE: 0.1257 std (0.0288). 3.18x fold improvement\n",
      "\n",
      "Dataset: Si_TM\n",
      "Mean MSE: 1.0345e-01 std (2.1553e-01). 1.37x fold improvement\n",
      "Mean R2: 0.9999 std (0.0003). 1.00x fold improvement\n",
      "Mean RMSE: 0.2035 std (0.2785). 1.84x fold improvement\n",
      "Mean MAE: 0.0871 std (0.0670). 3.56x fold improvement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_entire_wave_dfs = {}\n",
    "for dat in [\"Ti_TM\", \"Ti_TE\", \"Si_TE\", \"Si_TM\"]:\n",
    "    result_list = []\n",
    "    fold_i = 0\n",
    "    for train_data_pca, train_target, test_data_pca, test_target in PC_folds[dat]:\n",
    "        # now we want to use the entire wave data\n",
    "        # Fit a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_data_pca, train_target)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(test_data_pca)\n",
    "        # Calculate MSE, R2, RMSE, MAE\n",
    "        mse = mean_squared_error(test_target, y_pred)\n",
    "        r2 = r2_score(test_target, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(test_target - y_pred))\n",
    "        # Append results to the list\n",
    "        result_list.append({\n",
    "            \"mse\": mse,\n",
    "            \"r2\": r2,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"fold\": fold_i,\n",
    "        })\n",
    "        fold_i += 1\n",
    "    results_entire_wave_dfs[dat] = pd.DataFrame(result_list)\n",
    "\n",
    "# for each dataset we want to print the mean and std of the metrics for the best feature\n",
    "for dat in [\"Ti_TM\", \"Ti_TE\", \"Si_TE\", \"Si_TM\"]:\n",
    "    print(f\"Dataset: {dat}\")\n",
    "    # first group by feature to find the feature with lowest mean mse\n",
    "    mean_results = results_entire_wave_dfs[dat].agg({\n",
    "        \"mse\": [\"mean\",\"std\"],\n",
    "        \"r2\": [\"mean\",\"std\"],\n",
    "        \"rmse\": [\"mean\",\"std\"],\n",
    "        \"mae\": [\"mean\",\"std\"],\n",
    "    })\n",
    "    # mean_results.columns = [\"_\".join(col).strip() for col in mean_results.columns.values]\n",
    "    \n",
    "    # just print the mean and std\n",
    "    # calculate the fold improvement for mse compared to the best feature\n",
    "    fold_improvement = (mean_results[\"mse\"].values[0] / best_results[dat][\"mse_mean\"])**-1\n",
    "    print(f\"Mean MSE: {mean_results['mse'].values[0]:.4e} std ({mean_results['mse'].values[1]:.4e}). {fold_improvement:.2f}x fold improvement\")\n",
    "    fold_improvement = (mean_results[\"r2\"].values[0] / best_results[dat][\"r2_mean\"])**-1\n",
    "    print(f\"Mean R2: {mean_results['r2'].values[0]:.4f} std ({mean_results['r2'].values[1]:.4f}). {fold_improvement:.2f}x fold improvement\")\n",
    "    fold_improvement = (mean_results[\"rmse\"].values[0] / best_results[dat][\"rmse_mean\"])**-1\n",
    "    print(f\"Mean RMSE: {mean_results['rmse'].values[0]:.4f} std ({mean_results['rmse'].values[1]:.4f}). {fold_improvement:.2f}x fold improvement\")\n",
    "    fold_improvement = (mean_results[\"mae\"].values[0] / best_results[dat][\"mae_mean\"])**-1\n",
    "    print(f\"Mean MAE: {mean_results['mae'].values[0]:.4f} std ({mean_results['mae'].values[1]:.4f}). {fold_improvement:.2f}x fold improvement\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc72e73",
   "metadata": {},
   "source": [
    "# check the sv Si when using the peak shifts 1D datasets (Table 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d94b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_TE_1D = pd.read_excel(\"../p07_1D_SI_fitting/Si_TE_1Dfitting_4peaks.xlsx\", header=None)\n",
    "Si_TE_1D.columns = [\"target\",\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"]\n",
    "\n",
    "Si_TM_1D = pd.read_excel(\"../p07_1D_SI_fitting/Si_TM_1Dfitting_4peaks.xlsx\", header=None)\n",
    "Si_TM_1D.columns = [\"target\",\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"]\n",
    "\n",
    "Si_TE_1D_results = []\n",
    "Si_TM_1D_results = []\n",
    "# perform 5-fold cross validation on the 1D data\n",
    "fold_i = 0\n",
    "for train_index, test_index in kf.split(Si_TE_1D):\n",
    "    for df, result in zip([Si_TE_1D, Si_TM_1D],[Si_TE_1D_results, Si_TM_1D_results]):\n",
    "        train_data = df.iloc[train_index]\n",
    "        test_data = df.iloc[test_index]\n",
    "        for feat_name in [f\"feature_{i+1}\" for i in range(4)]:\n",
    "            X_train = train_data[feat_name].to_numpy()\n",
    "            y_train = train_data[\"target\"].values\n",
    "            X_test = test_data[feat_name].to_numpy()\n",
    "            y_test = test_data[\"target\"].values\n",
    "            # Fit a linear regression model\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train.reshape(-1, 1), y_train)\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "            # Calculate MSE, R2, RMSE, MAE\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = np.mean(np.abs(y_test - y_pred))\n",
    "            # now calculate the same metrics on the training data\n",
    "            y_train_pred = model.predict(X_train.reshape(-1, 1))\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = np.mean(np.abs(y_train - y_train_pred))\n",
    "            # Append results to the list\n",
    "            result.append({\n",
    "                \"feature\": feat_name,\n",
    "                \"mse\": mse,\n",
    "                \"r2\": r2,\n",
    "                \"rmse\": rmse,\n",
    "                \"mae\": mae,\n",
    "                \"fold\": fold_i,\n",
    "                \"mse.train\": mse_train,\n",
    "                \"r2.train\": r2_train,\n",
    "                \"rmse.train\": rmse_train,\n",
    "                \"mae.train\": mae_train,\n",
    "            })\n",
    "        # now we also want to try using all 4 features\n",
    "        X_train = train_data.drop(columns=[\"target\"]).to_numpy()\n",
    "        y_train = train_data[\"target\"].values\n",
    "        X_test = test_data.drop(columns=[\"target\"]).to_numpy()\n",
    "        y_test = test_data[\"target\"].values\n",
    "        # Fit a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate MSE, R2, RMSE, MAE\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(y_test - y_pred))\n",
    "        # now calculate the same metrics on the training data\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        mae_train = np.mean(np.abs(y_train - y_train_pred))\n",
    "        # Append results to the list\n",
    "        result.append({\n",
    "            \"feature\": \"all_features\",\n",
    "            \"mse\": mse,\n",
    "            \"r2\": r2,\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"fold\": fold_i,\n",
    "            \"mse.train\": mse_train,\n",
    "            \"r2.train\": r2_train,\n",
    "            \"rmse.train\": rmse_train,\n",
    "            \"mae.train\": mae_train,\n",
    "        })\n",
    "    fold_i += 1\n",
    "Si_TE_1D_result_df = pd.DataFrame(Si_TE_1D_results)\n",
    "Si_TM_1D_result_df = pd.DataFrame(Si_TM_1D_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf068bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae.train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_features</th>\n",
       "      <td>0.135694</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.366952</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.296414</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>0.121764</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.348838</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.280877</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>10.035007</td>\n",
       "      <td>1.843891</td>\n",
       "      <td>0.986622</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>3.157665</td>\n",
       "      <td>0.283188</td>\n",
       "      <td>2.729086</td>\n",
       "      <td>0.278675</td>\n",
       "      <td>8.801394</td>\n",
       "      <td>0.272485</td>\n",
       "      <td>0.989567</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>2.966428</td>\n",
       "      <td>0.046052</td>\n",
       "      <td>2.568578</td>\n",
       "      <td>0.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>1.822854</td>\n",
       "      <td>0.590767</td>\n",
       "      <td>0.997550</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>1.336948</td>\n",
       "      <td>0.210429</td>\n",
       "      <td>1.125622</td>\n",
       "      <td>0.127932</td>\n",
       "      <td>1.554510</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>0.998158</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.246267</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>1.057536</td>\n",
       "      <td>0.034875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>2.907157</td>\n",
       "      <td>0.638258</td>\n",
       "      <td>0.996132</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>1.697132</td>\n",
       "      <td>0.183369</td>\n",
       "      <td>1.436463</td>\n",
       "      <td>0.196374</td>\n",
       "      <td>2.599922</td>\n",
       "      <td>0.108381</td>\n",
       "      <td>0.996920</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.612147</td>\n",
       "      <td>0.033630</td>\n",
       "      <td>1.369071</td>\n",
       "      <td>0.052450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>0.562897</td>\n",
       "      <td>0.073247</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.749018</td>\n",
       "      <td>0.048342</td>\n",
       "      <td>0.604117</td>\n",
       "      <td>0.032712</td>\n",
       "      <td>0.512121</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.715551</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.582389</td>\n",
       "      <td>0.008291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mse                  r2                rmse            \\\n",
       "                   mean       std      mean       std      mean       std   \n",
       "feature                                                                     \n",
       "all_features   0.135694  0.026329  0.999824  0.000021  0.366952  0.036061   \n",
       "feature_1     10.035007  1.843891  0.986622  0.003594  3.157665  0.283188   \n",
       "feature_2      1.822854  0.590767  0.997550  0.000949  1.336948  0.210429   \n",
       "feature_3      2.907157  0.638258  0.996132  0.001105  1.697132  0.183369   \n",
       "feature_4      0.562897  0.073247  0.999250  0.000174  0.749018  0.048342   \n",
       "\n",
       "                   mae           mse.train            r2.train            \\\n",
       "                  mean       std      mean       std      mean       std   \n",
       "feature                                                                    \n",
       "all_features  0.296414  0.037559  0.121764  0.006810  0.999856  0.000008   \n",
       "feature_1     2.729086  0.278675  8.801394  0.272485  0.989567  0.000602   \n",
       "feature_2     1.125622  0.127932  1.554510  0.100828  0.998158  0.000142   \n",
       "feature_3     1.436463  0.196374  2.599922  0.108381  0.996920  0.000161   \n",
       "feature_4     0.604117  0.032712  0.512121  0.016505  0.999392  0.000044   \n",
       "\n",
       "             rmse.train           mae.train            \n",
       "                   mean       std      mean       std  \n",
       "feature                                                \n",
       "all_features   0.348838  0.009749  0.280877  0.010746  \n",
       "feature_1      2.966428  0.046052  2.568578  0.061155  \n",
       "feature_2      1.246267  0.040747  1.057536  0.034875  \n",
       "feature_3      1.612147  0.033630  1.369071  0.052450  \n",
       "feature_4      0.715551  0.011602  0.582389  0.008291  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall the best result using the entire wave data\n",
    "# Dataset: Si_TE\n",
    "# Mean MSE: 0.02473 std (9.9685e-03). ~22.7x fold improvement\n",
    "# Mean R2: 1.0000 std (0.0000). 1.00x fold improvement\n",
    "# Mean RMSE: 0.1547 std (0.0314). 3.14x fold improvement\n",
    "# Mean MAE: 0.1257 std (0.0288). 3.18x fold improvement\n",
    "\n",
    "Si_TE_1D_result_df.groupby(\"feature\").agg({\n",
    "    \"mse\": [\"mean\",\"std\"],\n",
    "    \"r2\": [\"mean\",\"std\"],\n",
    "    \"rmse\": [\"mean\",\"std\"],\n",
    "    \"mae\": [\"mean\",\"std\"],\n",
    "    \"mse.train\": [\"mean\",\"std\"],\n",
    "    \"r2.train\": [\"mean\",\"std\"],\n",
    "    \"rmse.train\": [\"mean\",\"std\"],\n",
    "    \"mae.train\": [\"mean\",\"std\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41cddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse.train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae.train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_features</th>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.065996</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>7.940732e-07</td>\n",
       "      <td>0.065707</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>0.791981</td>\n",
       "      <td>0.165257</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.886253</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>0.754197</td>\n",
       "      <td>0.086529</td>\n",
       "      <td>0.692697</td>\n",
       "      <td>0.027480</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>5.231713e-05</td>\n",
       "      <td>0.832152</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.710209</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>5.897534</td>\n",
       "      <td>1.077055</td>\n",
       "      <td>0.992177</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>2.421099</td>\n",
       "      <td>0.211578</td>\n",
       "      <td>2.103621</td>\n",
       "      <td>0.170806</td>\n",
       "      <td>5.226674</td>\n",
       "      <td>0.179268</td>\n",
       "      <td>0.993809</td>\n",
       "      <td>2.495997e-04</td>\n",
       "      <td>2.285918</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>2.005111</td>\n",
       "      <td>0.052579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>0.755887</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.867713</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.736634</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>0.668325</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>2.993195e-05</td>\n",
       "      <td>0.817464</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.014512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>0.029436</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.170650</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.137132</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>3.098957e-06</td>\n",
       "      <td>0.165218</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.132627</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mse                  r2                rmse            \\\n",
       "                  mean       std      mean       std      mean       std   \n",
       "feature                                                                    \n",
       "all_features  0.004556  0.001969  0.999994  0.000003  0.065996  0.015823   \n",
       "feature_1     0.791981  0.165257  0.998944  0.000304  0.886253  0.090394   \n",
       "feature_2     5.897534  1.077055  0.992177  0.001999  2.421099  0.211578   \n",
       "feature_3     0.755887  0.109434  0.998999  0.000221  0.867713  0.060837   \n",
       "feature_4     0.029436  0.006827  0.999961  0.000012  0.170650  0.019834   \n",
       "\n",
       "                   mae           mse.train            r2.train                \\\n",
       "                  mean       std      mean       std      mean           std   \n",
       "feature                                                                        \n",
       "all_features  0.053686  0.012416  0.004328  0.000483  0.999995  7.940732e-07   \n",
       "feature_1     0.754197  0.086529  0.692697  0.027480  0.999179  5.231713e-05   \n",
       "feature_2     2.103621  0.170806  5.226674  0.179268  0.993809  2.495997e-04   \n",
       "feature_3     0.736634  0.057786  0.668325  0.015962  0.999208  2.993195e-05   \n",
       "feature_4     0.137132  0.014416  0.027322  0.001810  0.999968  3.098957e-06   \n",
       "\n",
       "             rmse.train           mae.train            \n",
       "                   mean       std      mean       std  \n",
       "feature                                                \n",
       "all_features   0.065707  0.003633  0.051843  0.003193  \n",
       "feature_1      0.832152  0.016579  0.710209  0.019945  \n",
       "feature_2      2.285918  0.039535  2.005111  0.052579  \n",
       "feature_3      0.817464  0.009800  0.696552  0.014512  \n",
       "feature_4      0.165218  0.005523  0.132627  0.004225  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall the best result using the entire wave data\n",
    "# Dataset: Si_TM\n",
    "# Mean MSE: 0.1034 std (2.1553e-01). ~5x fold worsensing\n",
    "# Mean R2: 0.9999 std (0.0003). ~20% worse\n",
    "# Mean RMSE: 0.2035 std (0.2785). ~20% worse\n",
    "# Mean MAE: 0.0871 std (0.0670). ~2x fold improvement ?\n",
    "\n",
    "Si_TM_1D_result_df.groupby(\"feature\").agg({\n",
    "    \"mse\": [\"mean\",\"std\"],\n",
    "    \"r2\": [\"mean\",\"std\"],\n",
    "    \"rmse\": [\"mean\",\"std\"],\n",
    "    \"mae\": [\"mean\",\"std\"],\n",
    "    \"mse.train\": [\"mean\",\"std\"],\n",
    "    \"r2.train\": [\"mean\",\"std\"],\n",
    "    \"rmse.train\": [\"mean\",\"std\"],\n",
    "    \"mae.train\": [\"mean\",\"std\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2037ff6",
   "metadata": {},
   "source": [
    "# save the actual and fitted values for the best ML model for each dataset (Figure 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3c81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fitted_results_entire_wave_dfs = {}\n",
    "for dat in [\"Ti_TM\", \"Ti_TE\", \"Si_TE\", \"Si_TM\"]:\n",
    "    result_df = None\n",
    "    fold_i = 0\n",
    "    for train_data_pca, train_target, test_data_pca, test_target in PC_folds[dat]:\n",
    "        # now we want to use the entire wave data\n",
    "        # Fit a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_data_pca, train_target)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(test_data_pca)\n",
    "        \n",
    "        # now I want to create a dataframe with the true, predicted, and train/test labels\n",
    "        pred_fitted_test_df = pd.DataFrame({\n",
    "            \"true\": test_target,\n",
    "            f\"predicted_fold{fold_i}\": y_pred,\n",
    "            f\"train/test_fold{fold_i}\": [\"test\"] * len(test_target),\n",
    "        })\n",
    "        # now I want to create a dataframe with the true, predicted, and train/test labels for the training data\n",
    "        pred_fitted_train_df = pd.DataFrame({\n",
    "            \"true\": train_target,\n",
    "            f\"predicted_fold{fold_i}\": model.predict(train_data_pca),\n",
    "            f\"train/test_fold{fold_i}\": [\"train\"] * len(train_target),\n",
    "        })\n",
    "        # now I want to concatenate the two dataframes\n",
    "        pred_fitted_df = pd.concat([pred_fitted_train_df, pred_fitted_test_df])\n",
    "        fold_i += 1\n",
    "        if result_df is None:\n",
    "            result_df = pred_fitted_df\n",
    "        else:\n",
    "            result_df = result_df.merge(pred_fitted_df, on=\"true\", how=\"outer\")\n",
    "    pred_fitted_results_entire_wave_dfs[dat] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e1286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pred_fitted_results_entire_wave_dfs to a xlsx file one to a sheet\n",
    "with pd.ExcelWriter(\"pred_fitted_results_entire_wave_dfs.xlsx\") as writer:\n",
    "    for dat in pred_fitted_results_entire_wave_dfs.keys():\n",
    "        pred_fitted_results_entire_wave_dfs[dat].to_excel(writer, sheet_name=dat, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colorimetry_ML-6CtRR2jE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
